{1 Subprocess: abstractions for IO with unix processes}

{!Subprocess} is a module which attempts to make working with unix
processes in OCaml safer and simpler (in that order). 

{3 Safety features}

Several features are inlcuded in {!Subprocess} to improve the safety
and correctness of programs which launch other programs. It is not
perfect in this regard, but it does try to aliviate many of the common
pitfalls when working with processes.

{4 No Shell}

Commands in {!Subprocess} never recieve a shell. We've had enough
injection CEVs in the past several decades that it's time to stop
giving our commands a shell. I realize redirection tends to be a bit
easier to be a bit easier with a shell, but Subprocess provides
combinators to make it as easy as possible (but no easier!) to do IO
redirection--and indeed, this is the main point of the library.

The user is, of course free to do the equivalent of
[/bin/sh -c "echo foo"], i.e.
[Subprocess.cmd ["/bin/sh"; "-c"; "echo foo"]] but it's your own affair
at that point--and you're probably better off using functions provided
by the standard library or the [Unix] library at this point--but I
believe you will find that {!Subprocess} provides a better way to do 
most things.

{4 Non-zero exit status is (normally) an error}

Another "feature not a bug" of Subprocess is that, by default, a
non-zero exit status is considered a failure and will produce an error
in OCaml. In the top-level functions of the {!Subprocess} module, this
means raising an exception. If you, like me, prefer to handle errors
with result types, the {!Subprocess.Results} module is provided to
represent non-zero exit status as an [Error of] {!Subprocess.Exit.t}. A
combinator is provided convert this to [Error of string] for better
composition with other result types in the context of monadic binding.

However, I realize that a non-zero exit status is not always an error,
and for this, the {!Subprocess.Unchecked} module is provided. This
module is also useful if you are interested in the output of a process
regardless of the exit status.

{4 Cleanup is abstracted }

Suprocess attempts to avoid making the user handle closing processes
and pipes expliciitly by providing several functions which simply read
process output, close all pipes and wait for the process to exit before
returning the output (or error). There is also family of fold functions
which fold over line output from a running process, but clean
everything up before returning.

For running process interaction, the running process is passed to
a user-provided function and everything is properly closed when the
function exits--either by being fully evaluated or by raising an
exception.

If for some reason you need to pass around a live process in a wider
context, {!Subprocess.Exec.exec} makes this possible, but you have to
clean up your own mess at that point.

{3 Extras}

Subprocess generally does not use many any opaque types and practically
everything has a pretty printer for easier debugging. The lack of
opaque types is not an {i invitation} to go digging into the
implementation details  {i which are subject to change}, but rather an
acknowledgement that no abstraction is perfect and there may at times
valid reasons to dig into them.

{4 Opt-in non-blocking IO}

Subprocess supports non-blocking IO, but it does not provide direct
compatibility layers with popular OCaml ascynchronous IO libraries like
lwt and eio, which typically provide their own process abstractions.
Neither does Subprocess provide its own event loop. The user must
handle non-blocking IO operations and process polling manually where
non-blocking behavior is desired. It is not different from handling
non-blocking IO in the OCaml standard library and examples will be
provided here where relevant.

Perhaps compatibility with lwt and / or eio will be a goal for a future
version of Subprocess.

{2 Introductory examples}

{3 Commands }

The most fundamental abstraction in Subprocess is {!Subprocess.Cmd.t}
It is simply a data representation of a yet-to-be-executed command,
and contains information about arguments, I/O redirection, environment
variables and blocking.

{[
  # open Subprocess;;
  # let my_cmd = cmd ["echo"; "foo"];;
  val my_cmd : (stdin, stdout, stderr) Cmd.t = cmd(`echo foo`)
  # Format.printf "%a\n" Cmd.pp my_cmd;;
  cmd(`echo foo`)
]}

As you can see, the command also has type parameters related to each of
the standard streams, which both gives us more information as
programmers, but also turns certain failure cases for I/O into type
errors.

A number of combinators are defined after {!Subprocess.Core.val-cmd}
which may be used to redirect the standard streams, as well as set
environment variables and use non-blocking I/O for pipes. {i Subprocess
will either unblock all pipes or none. More on that later.} I typically
use the pipeline operator with this combinators because it "feels
right", but obviously you can use regular function application or
the [@@] application operator.

For example:

{[
(* similar to `my_cmd 2> /dev/null` *)
# my_cmd |> devnull_err;;
- : (stdin, stdout, devnull) Cmd.t = cmd(`echo foo`, stderr: /dev/null)
(* similar to `my_cmd < input.txt *)
# my_cmd |> file_in "input.txt";;
- : (file, stdout, stderr) Cmd.t = cmd(`echo foo`, stdin: file "input.txt")
(* similar to `USER=app my_cmd` *)
# my_cmd |> env ["USER=app"];;
- : (stdin, stdout, stderr) Cmd.t = cmd(`echo foo`, env:["USER=app"])
]}

{3 Execution Helpers}

Note that we have not yet executed any process. These combinators
simply produce a new instance of [Subprocess.Cmd.t]. How do we execute
commands? There are a variety of helper functions for this.

{[
# run my_cmd;;
foo
- : unit = ()
# read my_cmd;;
- : string = "foo\n" 
# lines my_cmd;;
- : string list = ["foo"]
# fold my_cmd ~init:0 ~f:(fun acc line -> acc + String.length line);;
- : int = 3
]}

There are many more such functions, starting with {!Subprocess.run}.
Remember that all the functions demonstrated here will throw an
exception on non-zero exit status. However, that all have analogous
versions in {!Subprocess.Results} and {!Subprocess.Unchecked} which
handle this case in different ways.

{[
# Results.read my_cmd;;
- : (string, Exit.t) result = Ok "foo\n"
# Unchecked.read my_cmd;;
- : Exit.t * string =
((exited: 0, pid: 13762, cmd(`echo foo`, stdout: pipe)), "foo\n")
]}

If you look closely at the exit information in the previous example,
you will also get a glimps of how the sausage is made. [my_cmd] has
its [stdout] set to the default (inheriting from the spawning process)
but the [read] function sets it to [pipe] internally which is necessary
to read the output into an OCaml string.

{4 {i on the benefits of expressive types}}

As already seen, commands carry type-level information about their
I/O streams. Whether you regard this as expressive or {i excessive} may
be a matter of taste, but a consequence of this is that not all
commands instances are valid with all of these process executor
fucntions. 

{[
# read (my_cmd |> file_out "out.txt");;
Error: This expression has type (stdin, file, stderr) Cmd.t
       but an expression was expected of type (stdin, stdout, 'a) Cmd.t
       Type file is not compatible with type stdout
]}

Here, [stdout] would be redirected twice, and from the perspective of someone
reading the code, this is ambigious in its meaning. Rather than let
inscrutable bugs creep into our code, we simply make such ambiguities
unrepresentable.

{3 Interacting with Running Processes (or [exec] and [let&])}

At times you may wish to interact with a running process, reading from
pipes iteratively or polling the process as you go. For itterating over
output, you may use [Subprocess.fold] and related functions, as we have
already seen. However as an illustrative example lets make the world's
most inefficient capitalize function.

{[
# 
let capitalize str = 
  exec (cmd ["tr"; "a-z"; "A-Z"] |> pipe_in |> pipe_out)
    ~f:(fun proc ->
      Out_channel.output_string (stdin proc) str;
      Out_channel.close (stdin proc);
      In_channel.input_all (stdout proc)
    );;
val capitalize : string -> string = <fun>
# capitalize "foo";;
- : string = "FOO"`
]}

Several important things here.

- [Subprocess.exit] takes a command as input in addition to a function.
  The function will take a handle to the process as input and will
  automatically close everything when the function exits.
- [Subprocess.stdin] and [Subprocess.stdout] are functions which will
  return [output_channel] and [input_channel] respectively if these
  streams have been set to [pipe]. As you might expect, there is also
  a [Subprocess.stderr] function for accessing the process's stderr.
  Trying to access a stream that is not a pipe with these functions is
  simply a type error.
- I/O with pipes is tricky. Though [exec] will automatically close any
  open pipes, it this we still have to explicity [close] or [flush]
  stdin in this this case or readding from stdout will block because
  the string will just be sitting in a buffer otherwise.

Also note that for longer inputs and outputs, we would want to use
non-blocking I/O to avoid these kinds of problems--a good case for
using {!Subprocess.fold_with}, which handles reads and writes
ascynchronously.
{[
# 
let capitalize str =
  fold_with (cmd ["tr"; "a-z"; "A-Z"]) ~lines:(Seq.return str) ~init:""
    ~f:( ^ );;
val capitalize : string -> string = <fun>
# capitalize "foo";;
- : string = "FOO"
]}

{4 creating process pipelines}

To simplify creating pipelines, [let&] another way to execute commands
with similar semantics to [exec]